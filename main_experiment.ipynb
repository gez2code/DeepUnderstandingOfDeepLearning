{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8h6k0mFWv/rjLbbhHNIz+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gez2code/DeepUnderstandingOfDeepLearning/blob/main/main_experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "id": "7DzAXqpjBiXX",
        "outputId": "fcac5c45-d55a-4942-a9f1-a915438d864e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/115.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m115.9/115.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mabraham-gezehei\u001b[0m (\u001b[33mabraham-gezehei-fachhochschule-nordwestschweiz-fhnw\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251225_102323-82vgorzz</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/abraham-gezehei-fachhochschule-nordwestschweiz-fhnw/DermaMNIST-Hybrid-Project/runs/82vgorzz' target=\"_blank\">Setup-Test-Run</a></strong> to <a href='https://wandb.ai/abraham-gezehei-fachhochschule-nordwestschweiz-fhnw/DermaMNIST-Hybrid-Project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/abraham-gezehei-fachhochschule-nordwestschweiz-fhnw/DermaMNIST-Hybrid-Project' target=\"_blank\">https://wandb.ai/abraham-gezehei-fachhochschule-nordwestschweiz-fhnw/DermaMNIST-Hybrid-Project</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/abraham-gezehei-fachhochschule-nordwestschweiz-fhnw/DermaMNIST-Hybrid-Project/runs/82vgorzz' target=\"_blank\">https://wandb.ai/abraham-gezehei-fachhochschule-nordwestschweiz-fhnw/DermaMNIST-Hybrid-Project/runs/82vgorzz</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Setup Complete! Check your WandB dashboard.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>‚ñÅ</td></tr><tr><td>loss</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.5</td></tr><tr><td>loss</td><td>1.2</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Setup-Test-Run</strong> at: <a href='https://wandb.ai/abraham-gezehei-fachhochschule-nordwestschweiz-fhnw/DermaMNIST-Hybrid-Project/runs/82vgorzz' target=\"_blank\">https://wandb.ai/abraham-gezehei-fachhochschule-nordwestschweiz-fhnw/DermaMNIST-Hybrid-Project/runs/82vgorzz</a><br> View project at: <a href='https://wandb.ai/abraham-gezehei-fachhochschule-nordwestschweiz-fhnw/DermaMNIST-Hybrid-Project' target=\"_blank\">https://wandb.ai/abraham-gezehei-fachhochschule-nordwestschweiz-fhnw/DermaMNIST-Hybrid-Project</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251225_102323-82vgorzz/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 1. Install the necessary libraries\n",
        "# - wandb: for experiment tracking\n",
        "# - medmnist: for the dataset\n",
        "!pip install -q wandb medmnist\n",
        "\n",
        "# 2. Import libraries\n",
        "import wandb\n",
        "from google.colab import userdata # This reads the secret key\n",
        "import os\n",
        "\n",
        "# 3. Login to WandB securely\n",
        "# This grabs the key you saved in the \"Secrets\" tab\n",
        "wandb_key = userdata.get('WANDB_API_KEY')\n",
        "wandb.login(key=wandb_key)\n",
        "\n",
        "# 4. Initialize the Project\n",
        "# This creates a project in your WandB dashboard\n",
        "run = wandb.init(\n",
        "    project=\"DermaMNIST-Hybrid-Project\",\n",
        "    name=\"Setup-Test-Run\",\n",
        "    notes=\"Testing if the lab environment works.\"\n",
        ")\n",
        "\n",
        "# 5. Log a dummy metric to make sure it works\n",
        "wandb.log({\"accuracy\": 0.5, \"loss\": 1.2})\n",
        "print(\"‚úÖ Setup Complete! Check your WandB dashboard.\")\n",
        "\n",
        "# 6. Finish the run\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# PHASE 2: DATA PIPELINE\n",
        "# ==========================================\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from medmnist import INFO, Evaluator\n",
        "import medmnist\n",
        "\n",
        "# 1. Define the Data Configuration\n",
        "# We use 'dermamnist' as requested by the professor\n",
        "data_flag = 'dermamnist'\n",
        "info = INFO[data_flag]\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])\n",
        "DataClass = getattr(medmnist, info['python_class'])\n",
        "\n",
        "print(f\"üìä Dataset Selected: {data_flag}\")\n",
        "print(f\"‚ÑπÔ∏è  Channels: {n_channels} | Classes: {n_classes}\")\n",
        "\n",
        "# 2. Preprocessing (The \"Transform\")\n",
        "# We convert images to Tensors (numbers) and Normalize them\n",
        "# Normalization (mean=0.5, std=0.5) helps the neural network learn faster\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "\n",
        "# 3. Download and Load the Data\n",
        "# 'download=True' ensures you get the files automatically\n",
        "train_dataset = DataClass(split='train', transform=data_transform, download=True)\n",
        "val_dataset = DataClass(split='val', transform=data_transform, download=True)\n",
        "test_dataset = DataClass(split='test', transform=data_transform, download=True)\n",
        "\n",
        "# 4. Create \"Data Loaders\"\n",
        "# These shuffle the data and feed it to the GPU in batches of 128 images at a time\n",
        "BATCH_SIZE = 128\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# 5. SANITY CHECK (Crucial Step!)\n",
        "# Always check the shape of your data before training\n",
        "images, labels = next(iter(train_loader))\n",
        "\n",
        "print(\"\\n‚úÖ Data Loading Successful!\")\n",
        "print(f\"üì¶ Batch Shape: {images.shape}\")\n",
        "print(f\"   -> This means: [Batch_Size, Channels, Height, Width]\")\n",
        "print(f\"üè∑Ô∏è Labels Shape: {labels.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUE4D_1QD9ft",
        "outputId": "200f52ad-6bd2-4302-bc02-94a73a128c74"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Dataset Selected: dermamnist\n",
            "‚ÑπÔ∏è  Channels: 3 | Classes: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19.7M/19.7M [00:44<00:00, 443kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Data Loading Successful!\n",
            "üì¶ Batch Shape: torch.Size([128, 3, 28, 28])\n",
            "   -> This means: [Batch_Size, Channels, Height, Width]\n",
            "üè∑Ô∏è Labels Shape: torch.Size([128, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# PHASE 3.1: THE TRAINING ENGINE\n",
        "# ==========================================\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "# Check device again to be safe\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"‚öôÔ∏è Engine running on: {device}\")\n",
        "\n",
        "def train_engine(model, model_name, epochs=10):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        model: The neural network to train\n",
        "        model_name: String name for the report (e.g. \"Baseline_CNN\")\n",
        "        epochs: How many times to loop through the data\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Initialize WandB for this specific run\n",
        "    wandb.init(\n",
        "        project=\"DermaMNIST-Hybrid-Project\",\n",
        "        name=f\"Run_{model_name}\",\n",
        "        config={\n",
        "            \"architecture\": model_name,\n",
        "            \"dataset\": \"DermaMNIST\",\n",
        "            \"epochs\": epochs,\n",
        "            \"batch_size\": 128,\n",
        "            \"learning_rate\": 0.001\n",
        "        },\n",
        "        reinit=True # Allows multiple runs in one notebook\n",
        "    )\n",
        "\n",
        "    # 2. Setup Optimizer & Loss Function\n",
        "    model = model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss() # Standard for classification\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    print(f\"\\nüöÄ Starting training for: {model_name}\")\n",
        "\n",
        "    # 3. The Training Loop\n",
        "    for epoch in range(epochs):\n",
        "        model.train() # Switch to training mode\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            # labels coming from MedMNIST might be [Batch, 1], we need [Batch]\n",
        "            labels = labels.squeeze().long()\n",
        "\n",
        "            # Zero gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass (Learning)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Metrics\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Calculate average metrics for this epoch\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        epoch_acc = correct / total\n",
        "\n",
        "        # Log to WandB (The \"Lab Notebook\")\n",
        "        wandb.log({\"epoch\": epoch, \"train_loss\": epoch_loss, \"train_acc\": epoch_acc})\n",
        "        print(f\"   [Epoch {epoch+1}/{epochs}] Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.4f}\")\n",
        "\n",
        "    # 4. Final Evaluation on Test Set\n",
        "    print(f\"üìù Evaluating {model_name} on Test Set...\")\n",
        "    model.eval() # Switch to eval mode (freezes layers like Dropout)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad(): # No need to calculate gradients for testing\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            labels = labels.squeeze().long()\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    test_acc = correct / total\n",
        "    print(f\"üèÜ Final Test Accuracy for {model_name}: {test_acc:.4f}\")\n",
        "\n",
        "    # Log final score to WandB\n",
        "    wandb.log({\"test_accuracy\": test_acc})\n",
        "    wandb.finish()\n",
        "\n",
        "    return model, test_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mo5GfyQVFhyX",
        "outputId": "3d8d4c8c-a30e-47db-f236-eb46386c04c0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚öôÔ∏è Engine running on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# PHASE 3.2: THE BASELINE MODEL\n",
        "# ==========================================\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        # Layer 1: Conv -> BatchNorm -> ReLU -> MaxPool\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        # Layer 2: Conv -> BatchNorm -> ReLU -> MaxPool\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        # Fully Connected Layer (Classifier)\n",
        "        # Image is 28x28. After two MaxPools (divide by 2 twice), it is 7x7.\n",
        "        # So input size is 32 channels * 7 * 7\n",
        "        self.fc = nn.Linear(32 * 7 * 7, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.view(out.size(0), -1) # Flatten the image into a vector\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "# --- RUN THE EXPERIMENT ---\n",
        "# 1. Instantiate the model\n",
        "baseline_model = SimpleCNN(num_classes=n_classes)\n",
        "\n",
        "# 2. Train it using our Engine\n",
        "trained_baseline, baseline_acc = train_engine(baseline_model, \"Baseline_CNN\", epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787
        },
        "id": "YySgbFi2F9MM",
        "outputId": "2edf8019-dbdb-4c31-b296-0c73e3e6cdc7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251225_103951-hm24r6ga</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/abraham-gezehei-fachhochschule-nordwestschweiz-fhnw/DermaMNIST-Hybrid-Project/runs/hm24r6ga' target=\"_blank\">Run_Baseline_CNN</a></strong> to <a href='https://wandb.ai/abraham-gezehei-fachhochschule-nordwestschweiz-fhnw/DermaMNIST-Hybrid-Project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/abraham-gezehei-fachhochschule-nordwestschweiz-fhnw/DermaMNIST-Hybrid-Project' target=\"_blank\">https://wandb.ai/abraham-gezehei-fachhochschule-nordwestschweiz-fhnw/DermaMNIST-Hybrid-Project</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/abraham-gezehei-fachhochschule-nordwestschweiz-fhnw/DermaMNIST-Hybrid-Project/runs/hm24r6ga' target=\"_blank\">https://wandb.ai/abraham-gezehei-fachhochschule-nordwestschweiz-fhnw/DermaMNIST-Hybrid-Project/runs/hm24r6ga</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üöÄ Starting training for: Baseline_CNN\n",
            "   [Epoch 1/10] Loss: 0.9316 | Acc: 0.6775\n",
            "   [Epoch 2/10] Loss: 0.7763 | Acc: 0.7206\n",
            "   [Epoch 3/10] Loss: 0.7183 | Acc: 0.7378\n",
            "   [Epoch 4/10] Loss: 0.6867 | Acc: 0.7488\n",
            "   [Epoch 5/10] Loss: 0.6570 | Acc: 0.7612\n",
            "   [Epoch 6/10] Loss: 0.6352 | Acc: 0.7688\n",
            "   [Epoch 7/10] Loss: 0.6125 | Acc: 0.7722\n",
            "   [Epoch 8/10] Loss: 0.6028 | Acc: 0.7749\n",
            "   [Epoch 9/10] Loss: 0.5843 | Acc: 0.7851\n",
            "   [Epoch 10/10] Loss: 0.5700 | Acc: 0.7885\n",
            "üìù Evaluating Baseline_CNN on Test Set...\n",
            "üèÜ Final Test Accuracy for Baseline_CNN: 0.7387\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà</td></tr><tr><td>test_accuracy</td><td>‚ñÅ</td></tr><tr><td>train_acc</td><td>‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà</td></tr><tr><td>train_loss</td><td>‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>test_accuracy</td><td>0.73865</td></tr><tr><td>train_acc</td><td>0.7885</td></tr><tr><td>train_loss</td><td>0.57004</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Run_Baseline_CNN</strong> at: <a href='https://wandb.ai/abraham-gezehei-fachhochschule-nordwestschweiz-fhnw/DermaMNIST-Hybrid-Project/runs/hm24r6ga' target=\"_blank\">https://wandb.ai/abraham-gezehei-fachhochschule-nordwestschweiz-fhnw/DermaMNIST-Hybrid-Project/runs/hm24r6ga</a><br> View project at: <a href='https://wandb.ai/abraham-gezehei-fachhochschule-nordwestschweiz-fhnw/DermaMNIST-Hybrid-Project' target=\"_blank\">https://wandb.ai/abraham-gezehei-fachhochschule-nordwestschweiz-fhnw/DermaMNIST-Hybrid-Project</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251225_103951-hm24r6ga/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# PHASE 3.3: THE COMPETITOR (ResNet-18)\n",
        "# ==========================================\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "def get_resnet_for_small_images(num_classes):\n",
        "    # 1. Load standard ResNet-18 Structure\n",
        "    # weights=None means we train from scratch (fair comparison with Baseline)\n",
        "    model = resnet18(weights=None)\n",
        "\n",
        "    # 2. THE HACK (Critical for MedMNIST)\n",
        "    # Original ResNet starts with an aggressive 7x7 conv and 2x2 pooling.\n",
        "    # We replace it with a gentle 3x3 conv and NO pooling to preserve our small 28x28 images.\n",
        "    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    model.maxpool = nn.Identity() # Remove the first maxpool\n",
        "\n",
        "    # 3. Modify the final classifier\n",
        "    # ResNet outputs 512 features, we need 'num_classes' outputs\n",
        "    model.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    return model\n",
        "\n",
        "# --- RUN THE EXPERIMENT ---\n",
        "print(\"üèóÔ∏è Building ResNet-18 Competitor...\")\n",
        "competitor_model = get_resnet_for_small_images(num_classes=n_classes)\n",
        "\n",
        "# 2. Train using the SAME engine (for fair comparison)\n",
        "# Note: This will take longer because ResNet is much deeper!\n",
        "trained_competitor, competitor_acc = train_engine(competitor_model, \"ResNet18_SOTA\", epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "JoFwOoBlHq-o",
        "outputId": "8f335207-3167-4ff7-f890-822c179def25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèóÔ∏è Building ResNet-18 Competitor...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to True."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Run_ResNet18_SOTA</strong> at: <a href='https://wandb.ai/abraham-gezehei-fachhochschule-nordwestschweiz-fhnw/DermaMNIST-Hybrid-Project/runs/zk3vaimf' target=\"_blank\">https://wandb.ai/abraham-gezehei-fachhochschule-nordwestschweiz-fhnw/DermaMNIST-Hybrid-Project/runs/zk3vaimf</a><br> View project at: <a href='https://wandb.ai/abraham-gezehei-fachhochschule-nordwestschweiz-fhnw/DermaMNIST-Hybrid-Project' target=\"_blank\">https://wandb.ai/abraham-gezehei-fachhochschule-nordwestschweiz-fhnw/DermaMNIST-Hybrid-Project</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251225_104718-zk3vaimf/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251225_105141-zo6wbfqe</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/abraham-gezehei-fachhochschule-nordwestschweiz-fhnw/DermaMNIST-Hybrid-Project/runs/zo6wbfqe' target=\"_blank\">Run_ResNet18_SOTA</a></strong> to <a href='https://wandb.ai/abraham-gezehei-fachhochschule-nordwestschweiz-fhnw/DermaMNIST-Hybrid-Project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/abraham-gezehei-fachhochschule-nordwestschweiz-fhnw/DermaMNIST-Hybrid-Project' target=\"_blank\">https://wandb.ai/abraham-gezehei-fachhochschule-nordwestschweiz-fhnw/DermaMNIST-Hybrid-Project</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/abraham-gezehei-fachhochschule-nordwestschweiz-fhnw/DermaMNIST-Hybrid-Project/runs/zo6wbfqe' target=\"_blank\">https://wandb.ai/abraham-gezehei-fachhochschule-nordwestschweiz-fhnw/DermaMNIST-Hybrid-Project/runs/zo6wbfqe</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üöÄ Starting training for: ResNet18_SOTA\n",
            "   [Epoch 1/10] Loss: 0.9336 | Acc: 0.6689\n",
            "   [Epoch 2/10] Loss: 0.7911 | Acc: 0.7087\n",
            "   [Epoch 3/10] Loss: 0.7476 | Acc: 0.7196\n",
            "   [Epoch 4/10] Loss: 0.6932 | Acc: 0.7408\n",
            "   [Epoch 5/10] Loss: 0.6733 | Acc: 0.7488\n"
          ]
        }
      ]
    }
  ]
}